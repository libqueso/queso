\chapter{Introduction}\label{ch-introduction}
\thispagestyle{headings}
\markboth{Chapter \ref{ch-introduction}: Introduction}{Chapter \ref{ch-introduction}: Introduction}

QUESO is a parallel object-oriented statistical library dedicated to the research of statistically robust, scalable, load balanced, and fault-tolerant mathematical algorithms for the quantification of uncertainty (UQ) of mathematical models and their predictions.
% It has been developed to implement advanced algorithms for Bayesian
% inference, including are many variants of MCMC and the multi-level algorithm.  It is able to handle uni- and multi-processor Linux
% environments and to provide a wide range of diagnostics.


The purpose of this chapter is to introduce relevant terminology, mathematical and statistical concepts, statistical algorithms, together with an overall description of how the user's application may be linked with the QUESO library.



\section{Preliminaries}


Statistical inverse theory reformulates inverse problems as problems of statistical inference by means of Bayesian statistics: all quantities are modeled as random variables, and probability distribution of the quantities encapsulates the uncertainty observed in their values. The solution to the inverse problem is then the probability distribution of the quantity of interest when all information available has been incorporated in the model. This (posterior) distribution describes the degree of confidence about the quantity after the measurement has been performed \cite{KaSo05}.

Thus, the solution to the statistical inverse problem may be given by Bayes' formula, which express the posterior distribution as a function of the prior distribution and the data represented through the likelihood function.

The likelihood function has an open form and its evaluation is highly computationally expensive.  Moreover, simulation-based posterior inference requires a large number of forward calculations to be performed, therefore fast and efficient sampling techniques are required for posterior inference.

It is often not straightforward to obtain explicit posterior point estimates of the solution, since it usually involves the evaluation of a high-dimensional integral with respect to a possibly non-smooth posterior distribution. In such cases, an alternative integration technique is the Markov chain Monte Carlo method: posterior means may be estimated using the sample mean from a series of random draws from the posterior distribution.

QUESO is designed in an abstract way so that it can be used by any computational model, as long as a likelihood function (in the case of statistical inverse problems) and a quantity of interest (QoI) function (in the case of statistical forward problems) is provided by the user application.

QUESO provides tools for both sampling algorithms for statistical inverse problems, following Bayes' formula, and statistical forward problems. It contains Monte Carlo solvers (for autocorrelation, kernel density estimation and accuracy assessment), MCMC (e.g. Metropolis Hastings \cite{Metr_1953,Hast_1970}) as well as the DRAM \cite{HaLaMiSa06} (for sampling from probability distributions); it also has the capacity to handle many chains or sequences in parallel, each chain or sequence itself demanding many computing nodes because of the computational model being statistically explored \cite{PrSc12}.

\section{Key Statistical Concepts}\label{sec:statistical_concepts}

A computational model is a combination of a
mathematical model and a discretization that enables the approximate
solution of the mathematical model using computer algorithms and  might be used in two different types of problems:
forward or inverse.

Any computational model is composed of a vector $\boldsymbol{\theta}$ of $n$ {\it parameters}, {\it state variables} $\mathbf{u}$, and {\it state equations} $\mathbf{r}(\boldsymbol{\theta},\mathbf{u}) = \mathbf{0}$.
Once the solution $\mathbf{u}$ is available, the computational model also includes extra functions for e.g.
the calculation of {\it model output data} $\mathbf{y} = \mathbf{y}(\boldsymbol{\theta},\mathbf{u})$, and the {\it prediction} of a
vector $\mathbf{q} = \mathbf{q}(\boldsymbol{\theta},\mathbf{u})$ of $m$~quantities~of~interest\text{ (QoI)},

Parameters designate all model variables that are neither state variables
nor further quantities computed by the model, such as: material properties, coefficients, constitutive parameters, boundary conditions, initial conditions,
external forces, parameters for modeling the model error, characteristics of an experimental apparatus (collection of devices and procedures),
discretization choices and numerical algorithm options.

% Some parameters might be directly measurable, e.g. room temperature,
% but some may not, e.g. a material property.
% Parameters that cannot be measured directly need to be {\it estimated}
% through the solution of an {\it inverse problem}.


In the case of a forward problem, the parameters $\boldsymbol{\theta}$ are given and
one then needs to compute $\mathbf{u}$, $\mathbf{y}$ and/or $\mathbf{q}$.
In the case of an inverse problem, however, experimental data $\mathbf{d}$ is given and
one then needs to {\it estimate} the values of the parameters $\boldsymbol{\theta}$ that
cause $\mathbf{y}$ to best fit  $\mathbf{d}$.
%where ``best'' is an algorithm dependent concept.

%The process of parameter estimation is also referred to as model calibration or model update, and it usually precedes the computation of a QoI, a process called model prediction.

Figure~\ref{fig-generic-problems} represents general inverse and forward problems respectively.
%
\begin{figure*}[htb]
\begin{minipage}[b]{0.5\textwidth}
\input{rawfigs/gfp01.latex}\\
\centering
(a)
\end{minipage}%\hfill
\begin{minipage}[b]{0.5\textwidth}
\input{rawfigs/gip01.latex}\\
\centering
(b)
\end{minipage}
%\end{center}
\vspace{-20pt}
\caption{The representation of (a) a generic forward problem and (b) a generic inverse problem.}
\label{fig-generic-problems}
\end{figure*}


There are many possible sources of uncertainty on a computational model. %procedures (a) and (b) above.
First, $\mathbf{d}$ need not be equal to the actual values of observables because of errors in the measurement process. Second, the values of the input parameters to the phenomenon might not be precisely known. Third, the appropriate set of
equations governing the phenomenon might not be well understood.

Computational models can be classified as either deterministic or stochastic -- which are the ones of interest here.  In deterministic models, all parameters are assigned numbers, and no parameter is related to the parametrization of a random variable (RV) or field. As a
consequence, a deterministic model assigns a number to each of the components of quantities $\mathbf{u}$, $\mathbf{y}$ and $\mathbf{q}$. In stochastic models, however, at least one parameter is assigned a probability density function (PDF) or is related to the parametrization of a RV or field, causing $\mathbf{u}$, $\mathbf{y}$ and $\mathbf{q}$ to become random variables.  Note that not all components of $\boldsymbol{\theta}$ need to be treated as random. As long as at least one component is random, $\boldsymbol{\theta}$ is a random vector, and the problem is stochastic.



In the case of forward problems, statistical forward problems can be represented very similarly to deterministic forward problems,
as seen in Figure \ref{fig-sfp-queso}.
In the case of inverse problems, as depicted in Figure \ref{fig-sip-queso}, however, the conceptual connection between deterministic and statistical problems
is not as straightforward.

\begin{figure}[h!]
\centerline{
\input{rawfigs/sfp01.latex}\\
}
\caption{
The representation of a statistical forward problem.
$\boldsymbol{\Theta}$ denotes a random variable related to parameters,
$\boldsymbol{\theta}$ denotes a realization of $\boldsymbol{\Theta}$ and
$\mathbf{Q}$ denotes a random variable related to quantities of interest.
}
\label{fig-sfp-queso}
\end{figure}

\begin{figure}[h!]
\centerline{
\input{rawfigs/sip01.latex}\\
}
\caption{
The representation of a statistical inverse problem.
$\boldsymbol{\Theta}$ denotes a random variable related to parameters,
$\boldsymbol{\theta}$ denotes a realization of $\boldsymbol{\Theta}$ and
$\mathbf{r}$ denotes model equations,
$\mathbf{y}$ denotes some model output data and
$\mathbf{d}$ denotes experimental data.
}
\label{fig-sip-queso}
\end{figure}


QUESO adopts a Bayesian analysis \cite{KaSo05, Ro04} for statistical inverse problems, interpreting the posterior PDF
\begin{equation}\label{eq-Bayes-solution}
\pi_{\text{posterior}}(\boldsymbol{\theta}|\mathbf{d})=\frac{\pi_{\text{prior}}(\boldsymbol{\theta})\pi_{\text{likelihood}}(\mathbf{d}|\boldsymbol{\theta})}{\pi(\mathbf{d})}
\end{equation}
as the solution. Such solutions combine the prior information $\pi_{\text{prior}}(\boldsymbol{\theta})$ of the parameters,
the information $\pi(\mathbf{d})$ on the data, and the likelihood $\pi_{\text{likelihood}}(\mathbf{d}|\boldsymbol{\theta})$ that the model computes certain data values with a given set of input parameters.

This semantic interpretation of achieving a posterior knowledge on the parameters (on the model)
after combining some prior model knowledge with experimental information provides an important mechanism for dealing with uncertainty.
Although mathematically simple, is not computationally trivial.

%
% \new{
%
%
%
% \section{Sampling the Posterior Density}
%
% The generation of a Markov chain of parameter vectors $\mathbf{m}\in\mathbb{R}^N$ demands at least the calculation of values $\mathcal{F}(\mathbf{m})$, where $\mathcal{F}$ is the misfit function.
% A chain generation algorithm might also need the quantities $\nabla\mathcal{F}(\mathbf{m})$ and ${\nabla}^2\mathcal{F}(\mathbf{m})$.
%
% Target pdf $\pi:\mathbb{R}^N\rightarrow\mathbb{R}$ with support $supp(\pi)$.
%
%
% \todo{\subsection{Misfit Functions $\mathcal{F}(\mathbf{m})$}}
%
% %
% %
% %
% % Let $\mathbf{m}=(A_1,E_1,\ldots,A_{N_{\text{mat}}},,E_{N_{\text{mat}}})$ be the vector of model parameters and $M=\mathbb{R}_{+}^{2N_{\text{mat}}}$ be the space of model parameters.
% % Let
% % $V_T$ denote the space of functions $f:\mathbb{R}_{+}\rightarrow\mathbb{R}_{+}$ that are weakly differentiable.
% % $V_T$ will be the space of temperature profiles.
% % Finally, let
% % $V_w$ denote the space of functions $f:\mathbb{R}_{+}\rightarrow[0,1]$ that are weakly differentiable.
% % $V_w$ will be the space of relative mass evolutions.
% % We will denote by
% % \begin{equation*}
% % w(\mathbf{m},T)\in V_w
% % \end{equation*}
% % the solution of \eqref{eq-composite-sum}-\eqref{eq-composite-initial-values} for given $\mathbf{m}\in M$ and $T\in V_T$.
% %
% % Let
% % $V_S$ denote the space of all functions $f:\mathbb{R}_{+}\rightarrow\mathbb{R}_{+}$ that are square-Lebesgue-integrable
% % over any finite interval.
% % $V_S$ will be the space of misfit weight functions.
% % Let
% % $V_{\sigma}$ denote the space of all functions $f:\mathbb{R}_{+}\rightarrow\mathbb{R}_+^{*}$ such that $1/f$ is square-Lebesgue-integrable
% % over any finite interval.
% % $V_{\sigma}$ will be the space of variance functions.
% %
% % Given a reference relative mass evolution function $\text{$d$}\in V_w$,
% % a temperature profile $T\in V_T$,
% % and some $t_{_{\text{F}}}>0$,
% % let $\mathcal{F}:M\rightarrow\mathbb{R}$ be the functional defined by
% % \begin{equation*}
% % \mathcal{F}(\mathbf{m}) = \int_{0}^{t_{_{\text{F}}}}~\left\{[w(\mathbf{m},T)](t)-\text{$d$}(t)\right\}^2\cdot S(t)~dt,
% % \end{equation*}
% % or simply
% % \begin{equation}\label{eq-F}
% % \mathcal{F}(\mathbf{m}) = \int_{0}^{t_{_{\text{F}}}}~(w-d)^2\cdot S~dt.
% % \end{equation}
% %
% %
% % The functional \eqref{eq-F} is general enough for our studies, since it can properly describe
% % not only the case where one has continuous measurements $\text{$d$}$,
% % but also the case of a finite set of $N_{\text{meas}}$ discrete measurements $0\leqslant d_j\leqslant 1$,
% % $1\leqslant i\leqslant N_{\text{meas}}$ at instants $0\leqslant t_1 < t_2 < \ldots < t_{N_{\text{meas}}}$.
% %
% % In the case of continuous measurements, for instance, one can set
% % \begin{equation*}
% % \mathcal{F}_1(\mathbf{m}) = \int_{0}^{t_{_{\text{F}}}}~\left\{[w(\mathbf{m},T)](t)-\text{$d$}(t)\right\}^2\cdot\frac{1}{\sigma^2(t)}~dt,
% % \end{equation*}
% % for some given variance function $\sigma^2\in V_S$ satisfying $\sigma(t)>0$ for all $t\geqslant 0$.
% %
% % On the other hand, when measurements are discrete and a corresponding finite set of variances $\sigma_j^2>0,~j=1,2,\ldots,N_{\text{meas}}$ is given, one can set
% % \begin{equation*}
% % \mathcal{F}_2(\mathbf{m}) = \int_0^{t_{_F}}~\{[w(\mathbf{m},T)](t)-\hat{d}(t)\}^2\cdot\left[\sum_{j=1}^{N_{\text{meas}}}\frac{\delta(t-t_j)}{{\hat{\sigma}}^2(t)}\right]~dt,
% % \end{equation*}
% % where
% % $\hat{d}\in V_w$ and $\hat{\sigma}\in V_{\sigma}$ are any functions satisfying
% % $\hat{d}(t_j)=d_j$ and $\hat{\sigma}(t_j)=\sigma_j$, $j=1,2,\ldots,N_{\text{meas}}$,
% % in which case the functional simply becomes
% % \begin{equation*}
% % \mathcal{F}_2(\mathbf{m}) = \sum_{j=1}^{N_{\text{meas}}}~\frac{\{[w(\mathbf{m},T)](t_j)-d_j\}^2}{\sigma_j^2},
% % \end{equation*}
% % assuming, without loss of generality, that $t_{_F}\geqslant t_{N_{\text{meas}}}$.
%
%
% \subsection{The Metropolis Hastings Algorithm}
%
% The inputs are:
% \begin{equation}\label{eq-inputs-MH-method}
% \left\{
% \begin{array}{cl}
% 1. & \text{Number }n_{\text{pos}}\geqslant 2\text{ of positions in the chain} \\
% 2. & \text{Initial guess }\mathbf{m}^{(0)} \\
% 3. & \text{Function }q:\mathbb{R}^N\times\mathbb{R}^N\rightarrow\mathbb{R}_{+},\text{ such that }q(\mathbf{a},\cdot)\text{ is a pdf for any }\mathbf{a}\in\mathbb{R}^N
% \end{array}
% \right.
% \end{equation}
%
% Let us define the function $\alpha:\mathbb{R}^N\times\mathbb{R}^N\rightarrow[0,1]$ defined by
% \begin{equation}\label{eq-alpha}
% \alpha(\mathbf{a},\mathbf{b})=\text{min}\left\{1,\frac{\pi(\mathbf{b})}{\pi(\mathbf{a})}\cdot\frac{q(\mathbf{b},\mathbf{a})}{q(\mathbf{a},\mathbf{b})}\right\}
% \end{equation}
%
% \begin{equation}\label{eq-MH-method}
% \left\{
% \begin{array}{cl}
% 01. & \text{Do }\{ \\
% 02. & \quad\underline{\text{{\bf Generate candidate}}}~\mathbf{c}\in\mathbb{R}^N\text{ by sampling }q(\mathbf{m}^{(k)},\cdot); \\
% 03. & \quad\text{If }\mathbf{c}\notin supp(\pi)\text{ then set }\mathbf{m}^{(k+1)}=\mathbf{m}^{(k)}; \\
% 04. & \quad\text{If }\mathbf{c}\in supp(\pi)\text{ then }\{ \\
% 05. & \quad\quad\underline{\text{{\bf Compute acceptance probability}}}~\alpha(\mathbf{m}^{(k)},\mathbf{c}); \\
% 06. & \quad\quad\text{Generate a sample }0 < \tau\leqslant 1\text{ from an uniform rv defined over }(0,1]; \\
% 07. & \quad\quad\text{If }\alpha<        \tau\text{ then set }\mathbf{m}^{(k+1)}=\mathbf{m}^{(k)}; \\
% 08. & \quad\quad\text{If }\alpha\geqslant\tau\text{ then set }\mathbf{m}^{(k+1)}=\mathbf{c}; \\
% 09. & \quad\} \\
% 10. & \quad\text{Set }k=k+1; \\
% 11. & \}\text{ while }(k+1 < n_{\text{pos}}).
% \end{array}
% \right.
% \end{equation}
%
% \subsection{The Metropolis Hastings Algorithm with Delayed Rejection}
%
% The inputs are:
% \begin{equation}\label{eq-inputs-DR-method}
% \left\{
% \begin{array}{cl}
% 1. & \text{Number }n_{\text{pos}}\geqslant 2\text{ of positions in the chain} \\
% 2. & \text{Initial guess }\mathbf{m}^{(0)} \\
% 3. & n_{\text{stages}}\geqslant 1 \\
% 4. & \text{For }1\leqslant i\leqslant n_{\text{stages}},\text{ functions }q_i:\underbrace{\mathbb{R}^N\times\ldots\times\mathbb{R}^N}_{(i+1)\text{ times}}\rightarrow\mathbb{R}_{+},\text{ such that } \\
%    & q_i(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)},\cdot)\text{ is a pdf for any }(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)})\in\underbrace{\mathbb{R}^N\times\ldots\times\mathbb{R}^N}_{i\text{ times}}
% \end{array}
% \right.
% \end{equation}
%
% We then recursively define
% \begin{equation}\label{eq-alphas}
% \alpha_i:\underbrace{\mathbb{R}^n\times\ldots\times\mathbb{R}^n}_{(i+1)\text{ times}}\rightarrow [0,1],\quad 1\leqslant i\leqslant n_{\text{stages}},
% \end{equation}
% by setting
% \begin{equation*}
% \alpha_1(\mathbf{a},\mathbf{x}^{(1)}) = \text{ min}
% \left\{
% 1,
% \frac
% {\pi(\mathbf{x}^{(1)})}
% {\pi(\mathbf{a})}
% \cdot
% \frac
% {q_1(\mathbf{x}^{(1)},\mathbf{a})}
% {q_1(\mathbf{a},\mathbf{x}^{(1)})}
% \right\},
% \end{equation*}
% and, for $i>1$,
% \begin{equation*}
% \alpha_i(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i)}) = \text{ min}
% \left\{
% 1,\frac
% {\pi(\mathbf{x}^{(i)})}
% {\pi(\mathbf{a})}
% \cdot q_{\text{fraction}}
% \cdot \alpha_{\text{fraction}}
% \right\}.
% \end{equation*}
% where
% the expressions $q_{\text{fraction}}$ and $\alpha_{\text{fraction}}$ are given by
% \begin{equation*}
% q_{\text{fraction}}=
% \frac
% {q_1(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)})}
% {q_1(\mathbf{a},\mathbf{x}^{(1)})}
% \frac
% {q_2(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\mathbf{x}^{(i-2)})}
% {q_2(\mathbf{a},\mathbf{x}^{(1)},\mathbf{x}^{(2)})}
% \ldots
% \frac
% {q_i(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\ldots,\mathbf{x}^{(1)},\mathbf{a})}
% {q_i(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)},\mathbf{x}^{(i)})}
% \end{equation*}
% and
% \begin{equation*}
% \alpha_{\text{fraction}}=
% \frac
% {[1-\alpha_1(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)})]}
% {[1-\alpha_1(\mathbf{a},\mathbf{x}^{(1)})]}
% \frac
% {[1-\alpha_2(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\mathbf{x}^{(i-2)})]}
% {[1-\alpha_2(\mathbf{a},\mathbf{x}^{(1)},\mathbf{x}^{(2)})]}
% \ldots
% \frac
% {[1-\alpha_{i-1}(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\ldots,\mathbf{x}^{(1)})]}
% {[1-\alpha_{i-1}(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)})]}.
% \end{equation*}
% It should be emphasized that $\mathbf{a}$ does {\it not} appear on the numerator of $\alpha_{\text{fraction}}$.
%
% \begin{equation}\label{eq-DR-method}
% \left\{
% \begin{array}{cl}
% 01. & \text{Do }\{ \\
% 02. & \quad\text{Set ACCEPT}=false\text{ and }i=1; \\
% 03. & \quad\text{Do }\{ \\
% 04. & \quad\quad \underline{\text{{\bf Generate candidate}}}~\mathbf{c}^{(i)}\in\mathbb{R}^N\text{ by sampling }q_i(\mathbf{m}^{(k)},\mathbf{c}^{(1)},\ldots,\mathbf{c}^{(i-1)},\cdot); \\
% 05. & \quad\quad\text{If }\mathbf{c}^{(i)}\notin supp(\pi)\text{ then set }i=i+1; \\
% 06. & \quad\quad\text{If }\mathbf{c}^{(i)}\in supp(\pi)\text{ then }\{ \\
% 07. & \quad\quad\quad \underline{\text{{\bf Compute acceptance probability}}}~\alpha_i(\mathbf{m}^{(k)},\mathbf{c}^{(1)},\ldots,\mathbf{c}^{(i-1)},\mathbf{c}^{(i)}); \\
% 08. & \quad\quad\quad \text{Generate a sample }0 < \tau\leqslant 1 \text{ from an uniform rv defined over }(0,1]; \\
% 09. & \quad\quad\quad \text{If }\alpha_i<        \tau\text{ then set }i=i+1; \\
% 10. & \quad\quad\quad \text{If }\alpha_i\geqslant\tau\text{ then set ACCEPT}=true; \\
% 11. & \quad\quad\} \\
% 12. & \quad\}\text{ while }(\text{ACCEPT==}false)\text{ and }(i\leqslant n_{\text{stages}}); \\
% 13. & \quad\text{If }(\text{ACCEPT}==true) \text{ then set }\mathbf{m}^{(k+1)}=\mathbf{c}^{(i)}; \\
% 14. & \quad\text{If }(\text{ACCEPT}==false)\text{ then set }\mathbf{m}^{(k+1)}=\mathbf{m}^{(k)}; \\
% 15. & \quad\text{Set }k=k+1; \\
% 16. & \}\text{ while }(k+1 < n_{\text{pos}}).
% \end{array}
% \right.
% \end{equation}
%
% }



\section{The Software Stack of an Application Using QUESO}
%TAKEN FROM QUESO PAPER, SECTION 3

% Section \ref{sc-concepts} identified many mathematical entities present in the description of statistical problems and in some algorithms used for their solution.
% As part of the design, QUESO attempts to conceptually implement these entities in order to allow algorithmic researchers to manipulate
% them at the library level, as well as for algorithm users (the modelers interested in UQ) to manipulate them at the application level.
% Examples of entities are
% vector space $\mathbb{R}^n$;
% vector subset $B\subset\mathbb{R}^n$;
% vector $\boldsymbol{\theta}\in B$;
% matrix $\mathbf{C}\in \mathbb{R}^n\times\mathbb{R}^n$;
% function $\pi:\mathbb{R}^n\rightarrow\mathbb{R}_+$, e.g. joint PDF;
% function $\pi:\mathbb{R}\rightarrow\mathbb{R}_+$, e.g. marginal PDF;
% function $\pi:\mathbb{R}\rightarrow[0,1]$, e.g. cumulative distribution function;
% realizer function;
% function $\mathbf{q}:\mathbb{R}^n\rightarrow\mathbb{R}^m$;
% sequences of scalars; and
% sequences of vectors.
% QUESO tries to naturally map such entities through an object-oriented design.
% Indeed, QUESO C++ classes include vector spaces, subsets, scalar sequences, PDFs, and RVs.


An application using QUESO falls into three categories: a statistical inverse problem (IP), a statistical forward problem (FP), or combinations of both.
In each problem the user might deal with up to five vectors of potentially very different sizes:
parameters $\boldsymbol{\theta}$, state $\mathbf{u}$, output $\mathbf{y}$, data $\mathbf{d}$ and QoIs $\mathbf{q}$.

Algorithms in the QUESO library require the supply
of a likelihood routine $\pi_{\text{like}}:\mathbb{R}^n\rightarrow\mathbb{R}_+$ for statistical inverse problems and
of a QoI routine $\mathbf{q}:\mathbb{R}^n\rightarrow\mathbb{R}^m$ for statistical forward problems. These routines
exist at the application level and provide the necessary bridge between the statistical algorithms in QUESO,
model knowledge in the model library and scenario and experimental data in the disk space.
%Concepts are further detailed in Chapter \ref{ch-introduction}.
%
Figure~\ref{fig-sw-stack} shows the software stack of a typical application that uses QUESO. In the figure, the symbol $\boldsymbol{\theta}$ represents a vector of $n\geqslant 1$ parameters.
%
\begin{figure}[!htbp]
\centerline{
\includegraphics[scale=0.4,clip=true]{figs/quesoSwStack_09_2010.png}
}
\caption{
An application software stack.
QUESO requires the input
%supply
of a likelihood routine $\pi_{\text{like}}:\mathbb{R}^n\rightarrow\mathbb{R}_+$ for IPs and
of a QoI routine $\mathbf{q}:\mathbb{R}^n\rightarrow\mathbb{R}^m$ for FPs.
These application level routines provide the bridge between
% among
the statistical algorithms in QUESO,
physics
%model
knowledge in the model library, and relevant
experimental (calibration
    and validation) data.
%model specific data in the disk space.
}
\label{fig-sw-stack}
\end{figure}

% \begin{figure}[h!]
% \centerline{
% \includegraphics[scale=0.50,clip=true]{figs/queso_paper1_03}
% }
% \caption{
% Overview of the software stack of a typical application that uses QUESO.
% The symbol $\boldsymbol{\theta}$ represents a vector of $n\geqslant 1$ parameters.
% Algorithms in the QUESO library require the supply
% of a likelihood routine $\pi_{\text{like}}:\mathbb{R}^n\rightarrow\mathbb{R}_+$ for statistical inverse problems and
% of a qoi routine $\mathbf{q}:\mathbb{R}^n\rightarrow\mathbb{R}^m$ for statistical forward problems. These routines
% exist at the application level and provide the necessary bridge between the statistical algorithms in QUESO,
% model knowledge in the model library and scenario and experimental data in the disk space.
% Concepts are further detailed in Chapter \ref{ch-introduction}.
% }
% \label{fig-sw-stack}
% \end{figure}
%
Even though QUESO deals directly with $\boldsymbol{\theta}$ and $\mathbf{q}$ only,
it is usually the case the one of the other three vectors ($\mathbf{u}$, $\mathbf{y}$ and $\mathbf{d}$) will have the biggest number of components and will therefore
dictate the size of the minimum parallel environment to be used in a problem.
%
So, for example, even though one processor might be sufficient for handling $\boldsymbol{\theta}$, $\mathbf{y}$, $\mathbf{d}$ and $\mathbf{q}$,
eight processors at least might be necessary to solve for $\mathbf{u}$.
QUESO currently only requires that the amounts $n$ and $m$ can be handled by the memory available to one processor,
which allows the analysis of problems with thousands of parameters and QoIs, a large amount even for state of the art UQ algorithms.

QUESO currently supports three modes of parallel execution:
an application user may simultaneously run:
\begin{description}
\item[(a)] multiple instances of a problem where the physical model requires a single processor, or
\item[(b)] multiple instances of a problem where the physical model requires multiple processors, or
\item[(c)] independent sets of types (a) and (b).
\end{description}

For example, suppose an user wants to use the Metropolis-Hastings (MH) algorithm to solve a statistical IP, and that 1,024 processors are available.
If the physical model is simple enough to be handled efficiently by a single processor, then the user can run 1,024 chains simultaneously, as in case (a).
If the model is more complex and requires, say, 16 processors, then the user can run 64 chains simultaneously, as in case (b), with 16 processors per chain.
QUESO treats this situation by using only 1 of the 16 processors to handle the chain.
When a likelihood evaluation is required, all 16 processors call the likelihood routine simultaneously.
Once the likelihood returns its value, QUESO puts  15 processors into idle state until the routine is called again or the chain completes.
Case (c) is useful, for instance, in the case of a computational procedure involving two models,
where a group of processors can be split into two groups, each handling one model.
Once the two-model analysis end, the combined model can use the full set of processors.\footnote{The parallel capabilities of QUESO have been exercised on the Ranger system of the TACC \cite{tacc} with up to 16k processors.}



\section{Algorithms for solving Statistical Inverse Problems}

The goal of inference is to characterize the posterior PDF, or to evaluate
point or interval estimates based on the posterior~\cite{HuMa01}.  Samples from
posterior can be obtained using Markov chain Monte Carlo (MCMC) which require
only pointwise evaluations of the unnormalized posterior.  The resulting
samples can then be used to either visually present the posterior or its
marginals, or to construct sample estimates of posterior expectations.
Examples of MCMC are: the Metropolis-Hastings (MH)
algorithm~\cite{Metr_1953,Hast_1970}, the Delayed Rejection (DR)
algorithm~\cite{GrMi01,Mira01}, and Adaptive Metropolis (AM)~\cite{HaSaTa01}
which are combined together in the Delayed Rejection Adaptive Metropolis, DRAM,
algorithm~\cite{HaLaMiSa06}. The DRAM is implemented in QUESO and available for
the solution of SIP. MCMC methods are well-established and
documented~\cite{CaSo07,GrMi01,HaLaMiSa06,HaSaTa01,Hast_1970,KaSo05,Laine08,Metr_1953,Mira01};
thus only brief description of the DRAM algorithm is presented in Section
\ref{sec:DRAM}.


During model construction, errors arising from imperfect modeling and
uncertainties due to incomplete information about the system and its
environment always exist; thus, there has been a crescent interest in Bayesian
model class updating  and selection
\cite{ChingChen2007,ChOlPr10,CheungPrudencio2012}.

Model updating refers to the methodology that determines the most plausible
model for a system, given a prior PDF. One stochastic method that handles model
updating successfully is the multilevel method. Throughout the years, sereveral
versions of the same method have been implemented as improvements of its
predecessors~\cite{BeckAu2002,ChingChen2007,CheungPrudencio2012}. QUESO hosts
the novel Adaptive Multilevel Stochastic Simulation Algorithm
(AMSSA)~\cite{CheungPrudencio2012}, which is described in Section
\ref{sec:ML:intro}. For details about the method, please refer to
\cite{CheungPrudencio2012}.

%\subsection{Markov chain Monte Carlo Algorithms}\label{sec:DRAM}


\subsection{DRAM Algorithm}\label{sec:DRAM}

DRAM is a combination of two ideas for improving the efficiency of
Metropolis-Hastings type Markov chain Monte Carlo (MCMC) algorithms, Delayed
Rejection and Adaptive Metropolis~\cite{DRAMtool}.

Random walk Metropolis-Hasting algorithm with Gaussian proposal distribution is
useful in simulating from the posterior distribution in many Bayesian data
analysis situations.
% For example, in large class of nonlinear models we can write the model as
% $$
% y = f(x;\btheta) + \varepsilon,\quad     \varepsilon \sim \mathcal{N}(0,I \sigma^2),
% $$
% where $y$ are indepndent observations of the system, with the expected behaviour described by the model function $f(x;\btheta)$, depending on control variables $x$ and model parameters $\btheta$ distribution.
%
In order for the chain to be efficient, the proposal covariance must somehow be
tuned to the shape and size of the target distribution. This is important in
highly nonlinear situations, when there are correlation between the components
of the posterior, or when the dimension of the parameter is high. The problem
of adapting the proposal distribution using the chain simulated so far is that
when the accepted values depend on the history of the chain, it is no longer
Markovian and standard convergence results do not apply. One solution is to use
adaptation only for the burn-in period and discard the part of the chain where
adaptation has been used. In that respect, the adaptation can be thought as
automatic burn-in. The idea of diminishing adaptation is that when adaptation
works well, its effect gets smaller and we might be able to prove the
ergodicity properties of the chain even when adaptation is used throughout the
whole simulation. This is the ideology behind AM adaptation. On the other hand,
the DR method allows the use of the the current rejected values without losing
the Markovian property and thus allows to adapt locally to the current location
of the target distribution.

In Adaptive Metropolis~\cite{HaSaTa01} the covariance matrix of the Gaussian
proposal distribution is adapted on the fly using the past chain. This
adaptation destroys the Markovian property of the chain, however, it can be
shown that the ergodicity properties of the generated sample remain. How well
this works on finite samples and on high dimension is not obvious and must be
verified by simulations.

Starting from initial covariance $C^{(0)}$, the target covariance is updated at
given intervals from the chain generated so far.
$$
%C_i = (cov(chain1:i) + I\delta)s,
C^{(i)} = s_d \, cov(\text{chain}_1:\text{chain}_i) + s_d \varepsilon I_d,
$$
the small number $\varepsilon$ prevents the sample covariance matrix from
becoming singular. For the scaling factor, the value $s_d = 2.4^2/d$ is
standard optimal choice for Gaussian targets, $d$ being the dimension of the
target~\cite{GelmanEtAl2004}. A standard updating formula for the sample
covariance matrix can be used, so that the whole chain does not need to reside
in the computer memory.

With the Delayed rejection method~\cite{Mira01}, it becomes possible to make
use of several tries after rejecting a value by using different proposals while
keep the reversibility of the chain. Delayed rejection method (DR) works in the
following way. Upon rejection a proposed candidate point, instead of advancing
time and retaining the same position, a second stage move is proposed. The
acceptance probability of the second stage candidate is computed so that
reversibility of the Markov chain relative to the distribution of interest is
preserved. The process of delaying rejection can be iterated for a fixed or
random number of stages, let's say $n_\text{stages}$. The higher stage
proposals are allowed to depend on the candidates so far proposed and rejected.
Thus DR allows partial local adaptation of the proposal within each time step
of the Markov chain still retaining the Markovian property and reversibility.

The first stage acceptance probability in DR is the standard MH acceptance and
it can be written as
\begin{equation*}
\alpha_1(\mathbf{a},\mathbf{x}^{(1)}) = \text{ min}
\left\{ 1,
\frac{\pi(\mathbf{x}^{(1)})}{\pi(\mathbf{a})} \cdot
\frac{q_1(\mathbf{x}^{(1)},\mathbf{a})}{q_1(\mathbf{a},\mathbf{x}^{(1)})}
\right\},
\end{equation*}

Here $\mathbf{a}$ is the current point, $\mathbf{x}^{(1)}$ is the proposed new
value drawn from the distribution $q_1(\mathbf{a}, \cdot)$, and $\pi$ is the
target distribution.  If $\mathbf{x}^{(1)}$ is rejected, a second candidate
$\mathbf{x}^{(2)}$ is drawn from $q_2(\mathbf{a}, \mathbf{x}^{(1)} , \cdot)$
using the acceptance probability
\begin{equation*}
\alpha_2( \mathbf{a}, \mathbf{x}^{(1)}, \mathbf{x}^{(2)}) =\min \left\{1,
\dfrac{\pi( \mathbf{x}^{(2)}) q_1( \mathbf{x}^{(2)}, \mathbf{x}^{(1)}) q_2( \mathbf{x}^{(2)}, \mathbf{x}^{(1)}, \mathbf{a})[1 - \alpha_1( \mathbf{x}^{(2)} , \mathbf{x}^{(1)} )]}{\pi( \mathbf{a}) q_1( \mathbf{a}, \mathbf{x}^{(1)}) q_2( \mathbf{a}, \mathbf{x}^{(1)}, \mathbf{x}^{(2)})[1 - \alpha_1 ( \mathbf{a}, \mathbf{x}^{(1)} )]}
\right\}
\end{equation*}
%
i.e., it depends not only on the current position of the chain but also on what
we have just proposed and rejected.

As the reversibility property is preserved, this method also leads to the same
stationary distribution $\pi$ as the standard MH algorithm. The procedure can
be iterated further for higher-stage proposals.
%
The Gaussian proposal at each stage $i$ is defined as:
\begin{equation} % Gamma_i esta embutido na formula do q_i
\label{eq:qi}
q_i(\underbrace{\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)}}_{i\text{ terms}},\mathbf{z})
=
e^{-\dfrac{1}{2}{\displaystyle \left\{[\mathbf{z}-\mathbf{a}]^T\cdot \left[\mathbf{C}\right]^{-1}\cdot[\mathbf{z}-\mathbf{a}]\right\}}}
\end{equation}

% \begin{equation*} % Gamma_i esta embutido na formula do q_i
% q_i(\underbrace{\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)}}_{i\text{ terms}},\mathbf{z})
% =
% e^{-\dfrac{1}{2}{\displaystyle \left\{[\mathbf{z}-\mathbf{a}]^T\cdot \left[\frac{1}{\gamma_i^2}\mathbf{C}\right]^{-1}\cdot[\mathbf{z}-\mathbf{a}]\right\}}}
% \end{equation*}
where the covariance matrix $\mathbf{C}$ and the scalings for the higher-stage
proposal covariances
$1=\gamma_1\leqslant\gamma_2\leqslant\ldots\leqslant\gamma_{n_{\text{stages}}}$
are given.


If $q_i$ denotes the proposal at the $i$-th stage, the acceptance probability
at that stage is:
\begin{equation}\label{eq-alphas}
\alpha_i(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i)}) = \text{ min}
\left\{1,
\frac {\pi(\mathbf{x}^{(i)})}{\pi(\mathbf{a})} \cdot q_{\text{fraction}} \cdot \alpha_{\text{fraction}}
\right\}.
\end{equation}
where the expressions $q_{\text{fraction}}$ and $\alpha_{\text{fraction}}$ are
given by
\begin{equation*}
q_{\text{fraction}}=
\frac{q_1(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)})}{q_1(\mathbf{a},\mathbf{x}^{(1)})}
\frac{q_2(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\mathbf{x}^{(i-2)})}{q_2(\mathbf{a},\mathbf{x}^{(1)},\mathbf{x}^{(2)})}
\ldots
\frac{q_i(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\ldots,\mathbf{x}^{(1)},\mathbf{a})}{q_i(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)},\mathbf{x}^{(i)})}
\end{equation*}
and
\begin{equation*}
\alpha_{\text{fraction}}=
\frac{[1-\alpha_1(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)})]}{[1-\alpha_1(\mathbf{a},\mathbf{x}^{(1)})]}
\frac{[1-\alpha_2(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\mathbf{x}^{(i-2)})]}{[1-\alpha_2(\mathbf{a},\mathbf{x}^{(1)},\mathbf{x}^{(2)})]}
\ldots
\frac{[1-\alpha_{i-1}(\mathbf{x}^{(i)},\mathbf{x}^{(i-1)},\ldots,\mathbf{x}^{(1)})]}{[1-\alpha_{i-1}(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)})]}.
\end{equation*}


Since all acceptance probabilities are computed so that reversibility with
respect to $\pi$ is preserved separately at each stage, the process of delaying
rejection can be interrupted at any stage that is, we can, in advance, decide
to try at most, say, 3 times to move away from the current position, otherwise
we let the chain stay where it is. Alternatively, upon each rejection, we can
toss a p-coin (i.e., a coin with head probability equal to p), and if the
outcome is head we move to a higher stage proposal, otherwise we stay
put~\cite{HaLaMiSa06}.

The smaller overall rejection rate of DR guarantees smaller asymptotic variance
of the estimates based on the chain. The DR chain can be shown to be
asymptotically more efficient that MH chain in the sense of Peskun ordering
(Mira, 2001a).

% Haario, et al. 2006 \cite{} combine AM and DR into a method called DRAM, in whzt they clain to me a straightforward possibility amonsgt the possible different implementations of the idea, which is decribed in this section.
% In order to be able to adapt the proposal at all you need some accepted points to start with. One ``master" proposal is tried first. After rejection, a try with modified version of the first proposal is done according to DR. A second proposal can be one with a smaller covariance, or with different orientation of the principal axes. The master proposal is adapted using the chain generated so far, and the second stage proposal follows the adaptation in obvious manner. %In the examples, and in the dramrun Matlab function, the second stage is just a scaled down version of the first stage proposal that itself is adapted according to AM.
%
%
% The DRAM may be considered a straightforward way of combining AM adaptation with a $m$-stages DR algorithm, by doing:
% i) the proposal at the first stage of DR is adapted just as in AM: the covariance $C^{(1)}$  is computed from the points of the
% sampled chain, no matter at which stage these points have been accepted in the sample path;
% ii0 the covariance $C^{(i)}$  of the proposal for the $i$-th stage ($i=2,\ldots, m$) is always computed simply as a scaled version
% of the proposal of the first stage, $C^{(i)} = \gamma_i C^{(1)}$; where the scale factors $\gamma_i$ can be somewhat freely chosen.
%
% ------------


Haario, et al. 2006 \cite{HaLaMiSa06} combine AM and DR into a method called
DRAM, in what they claim to be a straightforward possibility amongst the
possible different implementations of the idea, and which is described in this
section.

In order to be able to adapt the proposal, all you need some accepted points to
start with.
%

One ``master" proposal is tried first -- i.e., the proposal at the first stage
of DR is adapted just as in AM: the covariance $C^{(1)}$  is computed from the
points of the sampled chain, no matter at which stage these points have been
accepted in the sample path.  After rejection, a try with modified version of
the first proposal is done according to DR. A second proposal can be one with a
smaller covariance, or with different orientation of the principal axes. The
most common choice is to always compute the covariance $C^{(i)}$  of the
proposal for the $i$-th stage ($i=2,\ldots, n_\text{stages}$) simply as a
scaled version of the proposal of the first stage, $$C^{(i)} = \gamma_i
C^{(1)}$$ where the scale factors $\gamma_i$ can be somewhat freely chosen.
Then, the master proposal is adapted using the chain generated so far, and the
second stage proposal follows the adaptation in obvious manner.

%In the examples, and in the dramrun Matlab function, the second stage is just a scaled down version of the first stage proposal that itself is adapted according to AM.

The requirements for the DRAM algorithm are:
\begin{itemize}
 \item Number $n_{\text{pos}}\geqslant 2$ of positions in the chain;
 \item Initial guess $\mathbf{m}^{(0)}$;
 \item Number of stages for the DR method: $n_{\text{stages}}\geqslant 1$;
 \item For $1\leqslant i\leqslant n_{\text{stages}}$, functions $q_i:\underbrace{\mathbb{R}^N\times\ldots\times\mathbb{R}^N}_{(i+1)\text{ times}}\rightarrow\mathbb{R}_{+}$, such that $q_i(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)},\cdot)$ is a PDF for any $(\mathbf{a},\mathbf{x}^{(1)},\ldots,\mathbf{x}^{(i-1)})\in\underbrace{\mathbb{R}^N\times\ldots\times\mathbb{R}^N}_{i\text{ times}}$; i.e., choose $q_i$ as in Equation~\eqref{eq:qi};
 \item Recursively define $\alpha_i:\underbrace{\mathbb{R}^n\times\ldots\times\mathbb{R}^n}_{(i+1)\text{ times}}\rightarrow [0,1],\quad 1\leqslant i\leqslant n_{\text{stages}}$ according to Equation~\eqref{eq-alphas}.
\end{itemize}

% . Also, the Gaussian proposal at each stage $i$ is defined as:
% \begin{equation*}
% q_i(\underbrace{\mathbf{a},\mathbf{b},\ldots,\mathbf{y}}_{i\text{ terms}},\mathbf{z})
% =
% e^{-\frac{1}{2}{\displaystyle \left\{[\mathbf{z}-\mathbf{a}]^T\cdot \left[\frac{1}{\gamma_i^2}\mathbf{C}\right]^{-1}\cdot[\mathbf{z}-\mathbf{a}]\right\}}}
% \end{equation*}
% when the covariance matrix $\mathbf{C}$ and the ($n_{\text{stages}}$) numbers $1=\gamma_1\leqslant\gamma_2\leqslant\ldots\leqslant\gamma_{n_{\text{stages}}}$ are given.
%

Recalling that a sample is defined as:
\begin{equation*} % Gamma_i may or may not be embedded in the covariance matrix
% \text{a sample } = \mathbf{a}+\frac{1}{\gamma_i}\mathbf{C}^{1/2}\mathcal{N}(0,I).
\text{a sample } = \mathbf{a}+\mathbf{C}^{1/2}\mathcal{N}(0,I).
\end{equation*}
a simple, but useful, implementation of DRAM is described in Algorithm \ref{alg:DRAM}.


\begin{algorithm}[!hp]
\SetAlgoLined
\SetAlgoLined
\KwIn{Number of positions in the chain $n_{\text{pos}}\geqslant 2$; initial guess $\mathbf{m}^{(0)}$; initial first stage proposal covariance $C^{(0)}$; $n_{\text{stages}}\geqslant 1$; and functions $q_i:\underbrace{\mathbb{R}^N\times\ldots\times\mathbb{R}^N}_{(i+1)\text{ times}}\rightarrow\mathbb{R}_{+}$}
% \KwOut{}

Select $s_d$                  \tcp*[r]{scaling factor} \nllabel{alg01_s}
Select $\varepsilon$        \tcp*[r]{covariance regularization factor} \nllabel{alg01_eps}
Select $n_0$                \tcp*[r]{initial non-adaptation period}

\For(\tcp*[f]{$n_{\text{stages}}$ is the number of tries allowed}){$i\leftarrow 1$ \KwTo $n_{\text{stages}}$}
  {Select $\gamma_i$ \tcp*[r]{scalings for the higher-stage proposal covariances}}   \nllabel{alg01_vf_ft}

\Repeat{ ($k+1 < n_{\text{pos}}$ ) }{
 Set $ACCEPT \leftarrow false$\;
 Set $i \leftarrow 1$\;

 \tcp{After an initial period of simulation, adapt the master proposal (target) covariance using the chain generated so far:}
 \If{$k \geqslant n_0$}{
 $C^{(1)} = s_d Cov(\mathbf{m}^{(0)} ,\ldots, \mathbf{m}^{(k-1)}) + s_d \varepsilon I_d$\;
   }

 \tcp{$n_{\text{stages}}$-DR loop: }
 \Repeat{ (ACCEPT=false) and ($i \leqslant n_{\text{stages}}$)}{ %DR loop

Generate candidate $\mathbf{c}^{(i)}\in\mathbb{R}^N$ by sampling $q_i(\mathbf{m}^{(k)},\mathbf{c}^{(1)},\ldots,\mathbf{c}^{(i-1)},\cdot)$        \tcp*{$q_i$ is the proposal probability density}

\If {$\mathbf{c}^{(i)}\notin supp(\pi)$}{$i \leftarrow i+1 $}

\If {$\mathbf{c}^{(i)}\in supp(\pi)$}{
  Compute $\alpha_i(\mathbf{m}^{(k)},\mathbf{c}^{(1)},\ldots,\mathbf{c}^{(i-1)},\mathbf{c}^{(i)})$ \tcp*{acceptance probability}

  Generate a sample $\tau \sim \mathcal{U}\left((0,1]\right ) $ %$0 < \tau\leqslant 1$ from an uniform rv defined over $(0,1]$\;

  \lIf{ ($\alpha_i < \tau$)}{ $i\leftarrow i+1$}

  \lIf{ ($\alpha_i \geqslant\tau$)}{ACCEPT$\leftarrow$true}
  }

  $C^{(i)} = \gamma_i C^{(1)}$ \tcp*{Calculate the higher-stage proposal as scaled versions of~$C^{(1)}$, according to the chosen rule}

} %\Repeat{ (ACCEPT==false) and ($i \leqslant n_{\text{stages}}$)}{

\If{(\text{ACCEPT=true})}{ Set $\mathbf{m}^{(k+1)}\leftarrow \mathbf{c}^{(i)}$}

\If{(\text{ACCEPT=false})}{ Set $\mathbf{m}^{(k+1)} \leftarrow \mathbf{m}^{(k)}$}

Set $k \leftarrow k+1$\;

} % \Repeat{k+1 < n_{\text{pos}}}{

\caption{DRAM algorithm \cite{Laine08}.}\label{alg:DRAM}
\end{algorithm}



There are six variables in the QUESO input file used to set available options
for the DRAM algorithm, which are described in \ref{sec:MH}. Here, they are
presented presented bellow together with their respective definition in
Algorithm \ref{alg:DRAM}.
\begin{description}

 \item[\texttt{ip\_mh\_dr\_maxNumExtraStages}:] defines how many extra stages
   should be considered in the DR loop ($n_\text{stages}$);

 \item[\texttt{ip\_mh\_dr\_listOfScalesForExtraStages}:] defines the list $s$
   of scaling factors that will multiply the covariance matrix (values of
   $\gamma_i$ );


 \item[\texttt{ip\_mh\_am\_adaptInterval}:] defines whether or not there will
   be a period of adaptation;

   %the size of the interval in which each adapted proposal covariance matrix will be used;

 \item[\texttt{ip\_mh\_am\_initialNonAdaptInterval}:] defines the initial
   interval where the proposal covariance matrix will not be changed ($n_0$);

 \item[\texttt{ip\_mh\_am\_eta}:] is a factor used to scale the proposal
   covariance matrix, usually set to be $2.4^2/d$, where $d$ is the dimension
   of the problem~\cite{Laine08,HaLaMiSa06} ($s_d$);

 \item[\texttt{ip\_mh\_am\_epsilon}:] is the covariance regularization factor
   ($\varepsilon$).

\end{description}
%
% ; they are presented and explained in details in Sections \ref{sec:MH} and \ref{sec:gravity-input-file}}. The three examples in Chapter \ref{chap:Queso-examples}, ``simpleStatisticalInverseProblem'', ``gravity'' and ``validation cycle'' use DRAM to solve their SIP.


\subsection{Adaptive Multilevel Stochastic Simulation Algorithm}
\label{sec:ML:intro}


In this section we rewrite the Bayesian formula \eqref{eq-Bayes-solution} by
making explicit all the implicit model assumptions. Such explication demands
the use of probability logic and the concept of a stochastic system model class
(‘‘model class’’ for short); as these concepts enable the comparison of
competing model classes.

Let $M_j$ be one model class; the choice of $\bv{\theta} $ specifies a
particular predictive model in $M_j$, and, for brevity, we do not explicitly
write $\bv{\theta}_j $ to indicate that the parameters of different model
classes may be different, but this should be understood.  Based on $M_j$, one
can use data $D$ to compute the updated relative plausibility of each
predictive model in the set defined by $M_j$.  This relative plausibility is
quantified by the \textit{posterior} PDF $\pi(\boldsymbol{\theta}|\D,M_j)$.


Bayes’ theorem allows the update of the probability of each predictive model
$M_j$ by combining measured data $D$ with the prior PDF into the posterior PDF:
\begin{equation}
\begin{split}
\pi_\post (\bv{\theta}|\D, M_j) &= \dfrac{f(\D|\bv{\theta}, M_j) \cdot \pi_\prior (\bv{\theta} | M_j)}{\pi(\D, M_j)}
\\
&= \dfrac{f(\D|\bv{\theta}, M_j) \cdot \pi_\prior (\bv{\theta} | M_j)}{\int f(\D|\bv{\theta}, M_j) \cdot \pi_\prior (\bv{\theta} | M_j)\, d\bv{\theta}}
\end{split}
\end{equation}
where the denominator expresses the probability of getting the data $\D$ based
on $M_j$ and is called the evidence for $M_j$ provided by $\D$;
$\pi_\prior (\bv{\theta} | M_j)$ is the prior PDF of the predictive model
$\bv{\theta}$ within $M_j$; and the likelihood function $f(\D|\bv{\theta}, M_j)$
expresses the probability of getting $\D$ given the predictive model
$\bv{\theta}$ within $M_j$ -- and this allows stochastic models inside a model
class $M_j$ to be compared.




%\subsection{Intermediate distribution and evidence calculation}



When generating samples of posterior PDF $\pi_\post(\bv{\theta}|D,M_j) $ in
order to forward propagate uncertainty and compute QoI RV's, it is important to
take into account potential multiple modes in the posterior. One simple idea is
to sample increasingly difficult intermediate distributions, accumulating
``knowledge'' from one intermediate distribution to the next, until the target
posterior distribution is sampled.  In \cite{CheungPrudencio2012}, an advanced
stochastic simulation method, referred to as Adaptive Multi Level Algorithms,
is proposed which can generate posterior samples from
$\pi_\post (\bv{\theta}|\D, M_j)$ and compute the log of the evidence
$p(\D | \boldsymbol{\theta},M_j)$ at the same time by adaptively moving samples
from the prior to the posterior through an adaptively selected sequence of
intermediate distributions~\cite{ChOlPr10}.

Specifically, the intermediate distributions are given by:
\begin{equation}
\label{eq:intermediate_dist}
\pi_\text{int}^{(\ell)} (\bv{\theta}|\D) = f(\bv{\theta}|\D, M_j)^{\tau_\ell} \cdot \pi_\prior (\bv{\theta} | M_j), \quad \ell=0,1,\ldots,L,
\end{equation}
for a given $L > 0$ and a given sequence $0 = \tau_0 < \tau_1 < \ldots < \tau_L = 1$
of exponents.




In order to compute the model evidence $\pi( \D |M_j)$ where:
\begin{equation}
 \label{eq:evidence}
 \pi( \D |M_j)=\int f(\bv{\theta}|\D, M_j) \cdot \pi_\prior (\bv{\theta}|M_j) \, d\bv{\theta},
\end{equation}
the use of intermediate distribution is also beneficial.
For that, recall that
\begin{equation}
\label{eq:cl}
\begin{split}
 \pi( \D |M_j) &= \int f(\bv{\theta})\pi (\bv{\theta}) \, d\bv{\theta} \\
  &= \int f \; \pi \, d\bv{\theta} \\
  &= \int f^{1-\tau_{L-1}} f^{\tau_{L-1}-\tau_{L-2}}\ldots f^{\tau_2-\tau_1} f^{\tau_1}\; \pi \, d\bv{\theta} \\
  &= c_1 \int f^{1-\tau_{L-1}} f^{\tau_{L-1}-\tau_{L-2}}\ldots f^{\tau_2-\tau_1} \dfrac{f^{\tau_1}\; \pi}{c_1} \, d\bv{\theta} \\
  &= c_2 c_1 \int f^{1-\tau_{L-1}} f^{\tau_{L-1}-\tau_{L-2}}\ldots  \dfrac{f^{\tau_2-\tau_1} f^{\tau_1}\; \pi}{c_2 c_1} \, d\bv{\theta} \\
  &= c_L c_{L-1} \cdots c_2 c_1.
\end{split}
\end{equation}
Assuming that the prior PDF is normalized (it integrates to one) and if
$\tau_{\ell}$ is small enough, then Monte Carlo method can be efficiently
applied to calculate $c_{\ell}$ in Equation \eqref{eq:cl}. Due to numerical
(in)stability, it is more appropriate to calculate the estimators:
\begin{equation}
 \label{eq:log-cl}
 \tilde{c_i} = \ln c_i, \quad i=1,\ldots, L.
\end{equation}

Combining Equations \eqref{eq:cl} and \eqref{eq:log-cl}, we have:
\begin{equation*}
 \ln[\pi( \D |M_j)] = \tilde{c}_{L}+\tilde{c}_{L-1}+\ldots+\tilde{c}_2+\tilde{c}_1.
\end{equation*}


Computing the log of the evidence instead of calculating the evidence directly
is attractive because the evidence is often too large or too small relative to
the computer precision.
%
The posterior probability can be calculated readily in terms of the log
evidence, allowing overflow and underflow errors to be avoided
automatically~\cite{ChOlPr10}.
% In terms of the log evidence, the posterior
% probability is given by
% %
% \begin{equation} \label{ZEqnNumpost}
% P(M_j|D,M)=\frac{\exp[\ln \pi( \D |M_j)-E_{\max}]~P(M_j|M)}{\sum_{k=1}^{N_M}~\exp[\ln \pi( \D |M_k)-E_{\max}]~P(M_k|M)},
% \end{equation}
% %
% where $E_{\max}$ is the maximum of log evidences among the model classes in $M$:
% %
% \begin{equation} \label{maxln}
% E_{\max}=\max_{j\in[1,N_{M}]}\{\ln \pi( \D |M_j)\}.
% \end{equation}
% %


% \section{Auxiliary variables}

Now let's define some auxiliary variables for
$k=1,\ldots,n_\text{total}^{(\ell)}$:


\begin{itemize}
 \item $k$-th sample at the $\ell$-th level:
    \begin{equation}\label{eq:samples}
    \bv{\theta}^{(\ell) [k]},   \quad \ell=0,1,\ldots, L \\
    \end{equation}

 \item Plausibility weight:
    \begin{equation}
    \begin{split}\label{eq:w}
    w^{(\ell) [k]} &= \dfrac{f(\bv{\theta}^{(\ell) [k]}|\D, M_j)^{\tau_\ell} \cdot \pi_\prior (\bv{\theta}^{(\ell) [k]}, M_j)}{f(\bv{\theta}^{(\ell) [k]}|\D, M_j)^{\tau_\ell-1} \cdot \pi_\prior (\bv{\theta}^{(\ell) [k]}, M_j)}
		=\dfrac{f^{(\tau_{\ell})}(\D | \bv{\theta}^{(\ell) [k]}, M_j) }{f^{(\tau_{\ell-1})}(\D | \bv{\theta}^{(\ell) [k]}, M_j)}, \\
		&= f^{(\tau_{\ell}-\tau_{\ell-1})}(\D | \bv{\theta}^{(\ell) [k]}, M_j), \quad \ell=0,1,\ldots, L \\
    \end{split}
    \end{equation}

\item Normalized plausibility weight:
    \begin{equation}\label{eq:w-tilde}
    \tilde{w}^{(\ell) [k]} = \dfrac{w^{(\ell) [k]}}{\sum_{s=1}^{n_\text{total}^{(\ell)}}  w^{(\ell) [s]} }, \quad \ell=0,1,\ldots,L
    \end{equation}

\item Effective sample size:
    \begin{equation}\label{eq:neff}
    n_\text{eff}^{(\ell)} = \dfrac{1}{\sum_{s=1}^{n_\text{total}^{(\ell)}} \left( \tilde{w}^{(\ell) [s]}\right)^2}
    \end{equation}

\item Estimate for the sample covariance matrix for $\pi_\text{int}^{(\ell)}$:
    \begin{equation}\label{eq:est_cov}
     \Sigma = \sum_{m=1}^{n_\text{total}^{(\ell-1)}} \tilde{w}_{m} (\bv{\theta}^{(\ell-1) [m]} - \overline{\bv{\theta}}) (\bv{\theta}^{(\ell-1) [m]} - \overline{\bv{\theta}})^{t}, \quad \text{where} \quad
     \overline{\bv{\theta}} = \sum_{m=1}^{n_\text{total}^{(\ell-1)}}  \tilde{w}_{m} \bv{\theta}^{(\ell-1) [m]}
    \end{equation}

\end{itemize}


so we can define the discrete distribution:
\begin{equation}
 \label{eq:distribution}
 P^{(\ell)}(k) = \tilde{w}^{(\ell) [k]} , \quad k=1,2,\ldots, n_\text{total}^{(\ell)}.
\end{equation}


The ML algorithm consists of a series of resampling stages, with each stage
doing the following: given $n_\text{total}^{(\ell)}$ samples from
$\pi_\text{int}^{(\ell)} (\bv{\theta}|\D)$, denoted by
$\bv{\theta}^{(\ell)[k]}, k=1...n_\text{total}^{(\ell)}$ obtain samples from
$\pi_\text{int}^{(\ell+1)} (\bv{\theta}|\D)$, denoted by
$\bv{\theta}^{(\ell+1)[k]}, k=1...n_\text{total}^{(\ell+1)}$.

This is accomplished by: given the samples
$\bv{\theta}^{(\ell)[k]}, k=1...n_\text{total}^{(\ell)}$, in Equation \eqref{eq:samples}, from
$\pi_\text{int}^{(\ell)} (\bv{\theta}|\D)$, we compute the plausibility weights
$w^{(\ell) [k]}$ given in Equation \eqref{eq:w} with respect to
$\pi_\text{int}^{(\ell+1)} (\bv{\theta}|\D)$. Then we re-sample the uncertain
parameters according to the normalized weights $\tilde{w}^{(\ell) [k]}$, given
in Equation \eqref{eq:w-tilde}, through the distribution in Equation
\eqref{eq:distribution}. This is possible due to the fact that for large
$n_\text{total}^{(\ell)}$ and $n_\text{total}^{(\ell+1)}$, then
$\bv{\theta}^{(\ell+1)[k]}, k=1...n_\text{total}^{(\ell+1)}$ will be
distributed as $\pi_\text{int}^{(\ell+1)}
(\bv{\theta}|\D)$~\cite{ChingChen2007}.

The choice of $\tau_\ell, \ell=1,\ldots,L-1$ is essential. It is desirable to
increase the $\tau$ values slowly so that the transition between adjacent PDFs
is smooth, but if the increase of the $\tau$ values is too slow, the required
number of intermediate stages ($L$ value) will be too
large~\cite{ChingChen2007}. More intermediate stages mean more computational
cost.  In the ML method proposed by \cite{CheungPrudencio2012} and implemented
in QUESO, $\tau_\ell$ is computed through a bissection method so that:
\begin{equation}\label{eq:tau}
\beta_\text{min}^{(\ell)}<\dfrac{n_\text{eff}^{(\ell)}}{n_\text{total}^{(\ell)}} <\beta_\text{max}^{(\ell)}
\end{equation}
%A common threshold is $\approx 0.9 \, n_\text{total}^{(\ell-1)}$ \cite{Cheung2008}.


\subsubsection{AMSSA Algorithm}

% Recall that for $\ell=0$, then $\pi_\text{int}^{(\ell)} (\bv{\theta}|\D)=\pi_\prior (\bv{\theta} | M_j)$ and for $\ell=L$ then $\pi_\text{int}^{(\ell)} (\bv{\theta}|\D)= \pi_\post(\bv{\theta}|\D, M_j)$, thus the series of intermediate PDFs start from the prior PDF and ends with the posterior PDF.
Based on the above results, and recalling that the series of intermediate PDFs,
$\pi_\text{int}^{(\ell)} (\bv{\theta}|\D)$, start from the prior PDF and ends
with the posterior PDF,  Algorithm \ref{alg:ML} can be applied both to draw
samples from the posterior PDF, $\pi_\post (\bv{\theta}|\D, M_j)$, and to
estimate the evidence $\pi( \D ,M_j)$.

\begin{algorithm}[!htb]
%\AlFnt
\SetAlgoLined
\SetAlgoLined
\KwIn{for each $\ell=0,\ldots,L$: the total amount of samples to be generated at $\ell$-th level ($n_\text{total}^{(\ell)}>0$) and the thresholds ($0<\beta_\text{min}^{(\ell)}<\beta_\text{max}^{(\ell)}<1$) on the effective sample size of the $\ell$-th level}

%\KwOut{The n-th sample for $\bv{\theta}$ with the target PDF $\pi_\text{int}^{(\ell)}$. }

\KwOut{ $\bv{\theta}^{(m) [k]}, k=1,\ldots,n_\text{total}^{(m)}$; which are  asymptotically distributed as  $\pi_\post(\bv{\theta}|\D, M_j)$}

\KwOut{$\prod_{\ell} c_{\ell}$; which is asymptotically unbiased for $\pi( \D ,M_j)$ }

Set $\ell=0$\;

Set $\tau_\ell =0 $\;

Sample prior distribution, $\pi_\prior (\bv{\theta} | M_j)$, $n_\text{total}^{(0)}$ times  \tcp*[r]{i.e,
obtain $\bv{\theta}^{(0) [k]}, k=1,\ldots,n_\text{total}^{(0)}$}

\While{$\tau_\ell < 1$}{

 \tcc{At the beginning of the $\ell$-th level, we have the samples $\bv{\theta}^{(\ell-1)[k]}, k=1...n_\text{total}^{(\ell-1)}$ from  $\pi_\text{int}^{(\ell-1)} (\bv{\theta}|\D)$, Equation \eqref{eq:intermediate_dist}. }

 Set $\ell \leftarrow \ell + 1 $                  \tcp*[r]{begin next level}

 Compute plausibility weights $w^{(\ell) [k]}$ via Equation \eqref{eq:w}\;
 Compute normalized  weights $\tilde{w}^{(\ell) [k]}$ via Equation \eqref{eq:w-tilde}\;
 Compute $n_\text{eff}^{(\ell)}$ via Equation \eqref{eq:neff}\;

 Compute $\tau_\ell$ so that Equation \eqref{eq:tau} is satisfied\;
 \If{$\tau_\ell>1$}{
    $\tau_\ell \leftarrow 1$\;
    Recompute  $w^{(\ell) [k]}$ and  $\tilde{w}^{(\ell) [k]}$\;
 }

 Compute an estimate for the sample covariance matrix for $\pi_\text{int}^{(\ell)}$ via Equation \eqref{eq:est_cov}\;

%  Compute $c_{\ell} =\frac{1}{ n_\text{total}^{(\ell-1)}}  \left( \sum_{s=1}^{n_\text{total}^{(\ell-1)}} w_{s} \right)$ \tcp*[r]{recall that $\pi( \D |M_j) = \prod_{\ell} c_{\ell}$, Equation \eqref{eq:evidence}}

 Select, from previous level, the initial positions for the Markov chains\;  \nllabel{alg:ML:initialpos}

 Compute sizes of the chains         \tcp*[r]{the sum of the sizes $=n_\text{total}^{(\ell)}$} \nllabel{alg:ML:computechainsize}

 Redistribute chain initial positions among processors\; \nllabel{alg:ML:redist}

 \tcc{Then the $n_\text{total}^{(\ell)}$ samples $\bv{\theta}^{(\ell)[k]}$, from $\pi_\text{int}^{(\ell)}(\bv{\theta})$ are generated by doing the following for  $k=1,\ldots,n_\text{total}^{(\ell)}$:}

 Generate chains: draw a number $k'$ from a discrete distribution $P^{(\ell)}(k)$ in Equation \eqref{eq:distribution} via Metropolis-Hastings \tcp*[r]{i.e., obtain $\bv{\theta}^{(\ell) [k]}= P^{(l)[k]}$}

 Compute $c_{\ell} =\frac{1}{ n_\text{total}^{(\ell-1)}}  \left( \sum_{s=1}^{n_\text{total}^{(\ell-1)}} w_{s} \right)$ \tcp*[r]{recall that $\pi( \D |M_j) = \prod_{\ell} c_{\ell}$, Equation \eqref{eq:evidence}}

 }
\caption{Detailed description of the  Adaptive Multilevel Stochastic Simulation Algorithm proposed by \cite{CheungPrudencio2012}.}\label{alg:ML}
\end{algorithm}
% \todo{Line \ref{alg:ML:sampling} on Algorithm \ref{alg:ML} uses Metropolis-Hastings algorithm for sampling ; i.e., Generate $\bv{\theta}^*$ from a Gaussian PDF with mean $\bv{\theta}^{(\ell-1)[s']}$ and covariance $\Sigma$ from Equation \eqref{eq:est_cov} ... pagina 202 da tese}




%
%  Using $\bv{\theta}^{(\ell-1)[s']}$ as the current sample, generate a sample $\bv{\theta}^{(\ell) [k]}$ for $\bv{\theta}$ by multi-group MCMC algorithms \nllabel{alg:ML:sampling}
%
%  Set $\bv{\theta}^{(\ell-1)[s']} =\bv{\theta}^{(\ell) [k]}$\;
%  \;
%
%  \tcc{AQUI: ver Joseph's pagina 201/219}
%  Select, from previous level, the initial positions for the Markov chains \tcp*[r]{using samples from SSS as starting points}  \nllabel{alg:ML:initialpos}


%
% \begin{algorithm}[!htb]
% \SetAlgoLined
% \SetAlgoLined
% \KwIn{for each $\ell=0,\ldots,L$: the total amount of samples to be generated at $\ell$-th level ($n_\text{total}^{(\ell)}>0$) and the thresholds ($0<\beta_\text{min}^{(\ell)}<\beta_\text{max}^{(\ell)}<1$) on the effective sample size of the $\ell$-th level}
% \KwOut{}
%
% Set $\ell=0$\;
% Set $\tau_\ell =0 $\;
% Sample prior distribution $n_\text{total}^{(0)}$ times  \tcp*[r]{i.e, obtain $\bv{\theta}^{(0) [k]}, k=1,\ldots,n_\text{total}^{(0)}$}
%
% \While{$\tau_\ell < 1$}{
%  Set $\ell \leftarrow \ell + 1 $                         \tcp*[r]{begin next level}
%  Compute plausability weights $w^{(\ell) [k]}$ via Equation \ref{eq:w-tilde}
%  Compute $\tau_\ell$ so that $\beta_\text{min}^{(\ell)}<\dfrac{n_\text{eff}^{(\ell)}}{n_\text{total}^{(\ell)}} <\beta_\text{max}^{(\ell)}$\;
%  Select, from previous level, the initial positions for the Markov chains\;  \nllabel{alg:ML:initialpos}
%  Compute sizes of the chains                             \tcp*[r]{the sum of the sizes $=n_\text{total}^{(\ell)}$} 	\nllabel{alg:ML:computechainsize}
%  Redistribute chain initial positions among processors\; \nllabel{alg:ML:redist}
%  Generate chains\;
%  Compute $c_\ell$\;
%  }
% \caption{Multilevel algorithm \cite{}.}\label{alg:ML}
% \end{algorithm}

Steps \ref{alg:ML:initialpos} and \ref{alg:ML:computechainsize} in Algorithm
\ref{alg:ML} are accomplished by sampling the distribution in
Equation~\eqref{eq:distribution} a total of $n_\text{total}^{(\ell)} $ times.
The selected indices $k$ determine the samples $\bv{\theta}^{(\ell) [k]}$ to be
used as initial positions, and the number of times an index $k$ is selected
determines the size of the chain beginning at $\bv{\theta}^{(\ell) [k]}$.


At each level $\ell$, many computing nodes can be used to sample the parameter
space collectively. Beginning with $\ell = 0$, the computing nodes:
(a) sample $\pi_\text{int}^{(\ell)}(\bv{\theta}|\bv{D}, M_j)$;
(b) select some of the generated samples (``knowledge'') to serve as initial positions of Markov chains for the next distribution $\pi_\text{int}^{(\ell+1)}(\bv{\theta}|\bv{D}, M_j)$; and
(c) generate the Markov chains for $\pi_\text{int}^{(\ell+1)}(\bv{\theta}|\bv{D}, M_j)$.

The process (a)--(b)--(c) continues until the final posterior distribution is
sampled.  As $\ell$ increases, the selection process tends to value samples
that are located in the regions of high probability content, which gradually
``appear''as  $\tau_\ell$ increases. So, as $\ell$ increases, if the ``good''
samples selected from the  $\ell$-th level to the ($\ell$+1)-th level are not
redistributed among computing nodes before the Markov chains for the (
$\ell$+1)-th level are generated, the ``lucky'' computing nodes (that is, the
ones that had, already at the initial levels, samples in the final posterior
regions of high probability content) will tend to accumulate increasingly more
samples in the next levels. This possible issue is avoided maintaining a
balanced computational load among all computing nodes, which is handled in the
ML by the step in Line \ref{alg:ML:redist}.

Running the step in Line \ref{alg:ML:redist} of Algorithm \ref{alg:ML} is then
equivalent of solving the following problem: given the number of processors
$N_p$, the total number of runs $n_\text{total}$ and the number of runs $n_j$
(to be) handled by the $j$-th processor; distribute $N_t$ tasks among the $N_p$
processors so that each processor gets its total number $n_j$ of program runs,
$j = 1, \ldots, N_p$, the closest possible to the mean
$\bar{n}=n_\text{total}/N_p$. This parallel implementation of the algorithm is
proposed in \cite{CheungPrudencio2012}, and it has been implemented in QUESO by
the same authors/researchers.

%
% There are several approaches in how to paralellize the multilevel algorithm~\cite{BeckAu2002,ChingChen2007,Angelikopoulos2012}.
% The main problem in a straightforward parallel implementation, where each processor generates Markov chains independently for all $\tau_j$, is load imbalance.  Markov chains assigned to processors exploring high probability regions of the parameter space must generate a larger number of samples than those processors exploring low probability regions, leading to load imbalance as $\alpha_i \rightarrow 1$.  Thus, an important feature of the parallel implementation is the load
% balancing at each point in the $\tau_j$ sequence.  The parallel implementation of the algorithm is proposed in \cite{CheungPrudencio2012}, and it is implemented in QUESO by the same authors/researchers. The redistribution of the initial chain positions among the processors is represented by step \ref{alg:ML:redist} of on Algorithm \ref{alg:ML}.

\section{Algorithms for solving the Statistical Forward Problem}

The Monte Carlo method is commonly used for analyzing uncertainty propagation,
where the goal is to determine how random variation, lack of knowledge, or
error affects the sensitivity, performance, or reliability of the system that
is being modeled \cite{RoCa04}.

Monte Carlo works by iteratively evaluating a deterministic model using a set of
random numbers with known distribution.  The output can then be used to compute
empirical means, variances, or other higher-order moments.  \Queso's
implementation of the Monte Carlo algorithm is described in Algorithm
\ref{alg:MC}.

\begin{algorithm}[!htb]
  \SetAlgoLined
  \SetAlgoLined
  \KwIn{Samples $\{ x_i \}_{i=1}^N$ with known distribution $p$, and a known
    deterministic model $f$.}

  \KwOut{Set of propagated quantities $f_i$, $i = 1, \ldots, N$}

  \For{$i=0...N$}{
    Set $f_i \leftarrow f(x_i)$\;
  }

  \caption{Description of the Monte Carlo algorithm implemented in \Queso.}
  \label{alg:MC}
\end{algorithm}

Monte Carlo is implemented in QUESO and it is the chosen algorithm to compute a
sample of the output random variable (the QoI) of the statistical forward
problem for each given sample of the input random variable.

The output of Algorithm~\ref{alg:MC} can be used to compute empirical moments,
for example
%
\begin{equation*}
  \int f(x) p(x) \ud x \approx \frac{1}{N} \sum_{i=0}^N f(x_i),
  \quad x_i \sim p.
\end{equation*}
